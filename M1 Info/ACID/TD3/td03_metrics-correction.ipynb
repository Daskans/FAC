{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda022d9-b5f3-42cf-84de-9543ba21c25f",
   "metadata": {},
   "source": [
    "#### Université de Bordeaux,  Master Mention Informatique\n",
    "\n",
    "# Analyse, classification et indexation des données : feuille 4\n",
    "### Métriques d'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb5eda1-7056-4ae3-b27c-3fb5aec67bba",
   "metadata": {},
   "source": [
    "### Présentation\n",
    "\n",
    "L'objectif de ce TD est de comprendre les métriques d'évaluation des modèles de machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373820f8-2064-4d75-81cc-5c31fda8e339",
   "metadata": {},
   "source": [
    "### Exercice 1.\n",
    "On dispose d'un corpus de données $D = (x_i, y_i)_{1\\leq i \\leq n}$. On partitionne alors $D$ en deux ensembles :\n",
    "$$\n",
    "D = Train \\cup Test\n",
    "$$\n",
    "Le sous ensemble $Train$ est alors utilisé pour entrainer un modèle $M$ alors que $Test$ est lui utilisé pour tester $M$\n",
    "\n",
    "1. Rappeler la définition de la matrice de confusion \n",
    "2. On se limite au cas d'une classification binaire. Donner, en fonction du contenu de la matrice de confusion les expressions de l'$accuracy$, la $precision$, le $recall$ et le $F_1 score$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e11df6-ac02-4a5d-8155-ce2dee2ddfc3",
   "metadata": {},
   "source": [
    "### Exercice 2.\n",
    "\n",
    "On dispose de données (images IRM) relatives à des personnes atteintes (ou pas) de cancer. On entraîne alors un modèle pour détecter d'éventuelles cellules cancereuses sur les images. Celles-ci sont alors classifiées $1$ pour les images positives (patient atteint de cancer) et $0$ pour les images négatives.\n",
    "\n",
    "On a ensuite testé le modèle sur des données d'autres patients pour lesquels le diagnostic est connu. Le résultat peut être récupéré à l'adresse \n",
    "\n",
    "<code>https://www.labri.fr/perso/zemmari/datasets/y_test_pred.csv</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6454ce9-8f4f-4ac9-946d-2edb06d3436a",
   "metadata": {},
   "source": [
    "#### Question 1.\n",
    "\n",
    "Ecrire le code nécessaire pour charger le contenu du fichier dans un <code>DataFrame y</code>. On peut récupérer les premières lignes de <code> y </code> avec <code>y.head()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b7bd9-d5b8-48f5-bf5f-c3b6b1720161",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CORRECTION\n",
    "import pandas as pa\n",
    "\n",
    "y = pa.read_csv('https://www.labri.fr/perso/zemmari/datasets/y_test_pred.csv')\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd037cdf",
   "metadata": {},
   "source": [
    "Tester le code suivant pour apprendre comment accéder à une colonne d'un DataFrame et la transformer en numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vt = y[\"vt\"]\n",
    "y_vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5be039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array(y_vt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8c4f6-9a1e-443d-b9e8-33b1afc77529",
   "metadata": {},
   "source": [
    "#### Question 2.\n",
    "Ecrire une fonction <code>compute_confusion_matrix(y_vt, y_vp)</code> permettant de calculer la matrice de confusion entre la vérité terrain <code>y_vt</code> et les prédictions <code>y_vp</code> (données dans le format pandas). La matrice de confusion calculée sera un numpy array 2x2.\n",
    "\n",
    "*Indication :*  la fonction <code>logical_and(exp1, exp2)</code> du package <code>numpy</code> retourne <code>1</code> si les deux expressions sont vraies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f6265-dc0f-4e13-94df-b6bc63b19b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CORRECTION\n",
    "\n",
    "def compute_confusion_matrix(y_vt, y_vp):\n",
    "    y_true = np.array(y_vt)\n",
    "    y_pred = np.array(y_vp)\n",
    "\n",
    "    tp = np.sum(np.logical_and(y_true == 1, y_pred == 1)) # positif => classe 1\n",
    "    tn = np.sum(np.logical_and(y_true == 0, y_pred == 0))\n",
    "    fp = np.sum(np.logical_and(y_true == 0, y_pred == 1))\n",
    "    fn = np.sum(np.logical_and(y_true == 1, y_pred == 0))\n",
    "\n",
    "    return np.array([[tp, fn], [fp, tn]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf429ccb-19fe-4e9f-b720-f4bd91d5b4e9",
   "metadata": {},
   "source": [
    "Calculer la matrice de confusions des données ci-dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f4331-6835-4508-b96b-a4ef5455fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CORRECTION\n",
    "\n",
    "cm = compute_confusion_matrix(y['vt'], y['vp'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54ba4d-0f83-4e7e-beb1-f7c466ce5a1b",
   "metadata": {},
   "source": [
    "#### Question 3.\n",
    "Ecrire une fonction <code>compute_metrics(confusion_matrix)</code> permettant de calculer $accuracy$, la $precision$, le $recall$ et le $F_1 score$ à partir de la matrice de confusion donnée sous la forme d'un numpy array 2x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea4284-9e47-4b77-a26a-42811a1fb14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CORRECTION\n",
    "def compute_metrics(confusion_matrix):\n",
    "    tp, fn, fp, tn = confusion_matrix.flatten()\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c15a7-091a-4998-bdc6-f12e39479969",
   "metadata": {},
   "source": [
    "Utiliser la fonction pour évaluer le modèle. Qu'en pensez-vous ? Donner une interprétation de chacune des métriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e976e4-44de-4249-9308-365c886dec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CORRECTION\n",
    "acc, prec, rec, f1 = compute_metrics(cm)\n",
    "print(acc, prec, rec, f1)\n",
    "print('Accuracy: {:.2%}'.format(acc))\n",
    "print('Precision: {:.2%}'.format(prec))\n",
    "print('Recall: {:.2%}'.format(rec))\n",
    "print('F1 score: {:.2%}'.format(f1))\n",
    "\n",
    "# - accuracy 62% : la classification n'est pas très bonne\n",
    "# - precision 62% :  beaucoup de faux positifs, si on utilise le résultat de la classification comme diagnostic, \n",
    "#                   il y a 38% des gens à qui on dit qu'ils sont malades et qui ne le sont pas...\n",
    "# - recall 99% : il y a peu de faux négatifs, on va rarement dire à quelqu'un qu'il n'est pas malade alors qu'il l'est\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
